# Implementation Notes

## Runtime Details

The current scope is simply a JavaScript object and the Scheme scope chain is implemented through its
prototype property. Scheme code is generally invoked with "this" as the current scope, and it can
resolve any reference using this[ref]. Nothing could be simpler. Or faster.

Function closures do a lot of the heavy lifting here. For instance, Scheme closures are implemented
as JavaScript closures that capture the scope then apply the function with the captured scope. Scheme
lambdas are also compiled into JavaScript closures. Since a closure is a JavaScript function,
it can be called as an ordinary JavaScript function _whether it is compiled or not_. This is
the general case: Scheme functions can call any JavaScript function and JavaScript can call
any Scheme function. And since closures capture their scopes, they do not need to be invoked
with the "this" scope parameter.

The Scheme dialect is modelled roughly on SIOD since there is a corpus of existing code for
that dialect, but it could conceivably be extended in different directions; I'm leaning toward Clojure.
I _strongly_ prefer not to fork the implementation for dialects, but instead make the dialect an
instantiation option.

It proved difficult to keep JavaScript objects from sneaking into the SchemeJS environment
so I invited them in as first'class. SchemeJS is fully Scheme _and_ fully JavaScript.
It even has notations fof JavaScript Array and Object literals. Every JavaScript operator and global
symbol is available and usable in SchemeJS. Cons cells are JavaScript-iterables.
You can iterate over them using "for (let obj of list) ...".
SchemeJS does _not_ see iterables as Cons cells by default.
That would be too slow and semantically confusing.
But you can create a "list-view" wrapper that lazily invokes the iterator every time
"cdr" is invoked. That works just as well and doesn't tax ordinary list manipulation
primitives.

Scheme atoms are simply Symbols that happen to be in the ATOMS dictionary.

A Scheme instance is the global scope itself. Globally-defined Scheme values and functions
are the values of their Atoms, i.e. Symbols. JavaScript API methods are string-keyed, and
generally must be invoked as globalScope.apiName(), which is pretty much what you'd
do anyway.

The parser provides feedback to REPLs through a parseContext Array. REPLs can use the parseContext for
auto-indent and syntax highlighting if they desire. SchemeSJ comes with a Node.js CLI/REPL and
a Web REPL that are just simple embeddings of the SchemeJS module. All you need to do
is import it and create a global scope instance.

## Compiler

The compiler compiles a "binder" function that creates local variables containing any outside
values and function definitions since code generated by "new Function" can only see the global
scope. The binder is then invoked so that references can be resolved to things present in
the compilation scope. It returns the function itself, bindings resolved.

The compiler uses the builtin function definitions themselves as code-generation templates
in most cases. Special forms (with unevaluated arguments), requires a small code-generatin hook.
To see the compiled code, just invoke String(function), or (String function) in Scheme.
Templates are weaved together using something very much like SSA graphs and the "if" hook, for instance,
basically generates a "PHI" node. The result is JavaScript in 1-1 correspondence
between Scheme and the JavaScript you'd write yourself, except for a bunch of assignments
to SSA variables. The JavaScript JITs will certainly erase those variables.

JavaScript JITs will go to town on the generated code and since
teams of talented engineers have put countless man-years of effort into making JavaScript fast,
SchemeJS is very fast too.
I stand atop all that work hardly lifting a finger.

## Scheme JIT

Although currently optioned "off" by default (but tested in the unit tests)
there's a Scheme JIT that compiles interpreted functions after they have been
invoked a client-specified number of times.

A compiled SchemeJS function must necessarily "bind" the current values of the functions that
the compiled code embeds. Manualy invoking the compiler binds functions and nothing else but it's
understood that the current values of those functions are "pickled" into the compiled function.

The JIT must consider that a bound function might subsequently be redefined. So JITed functions enter through
a "guard" function that first checks whether the bound functions (and, potentially, values) have changed.
If they have, it bails out to the interpreter. Otherwise it enters the compiled code.

After bailing to the interpreter, the process begins again and after enough invocations the function
is compiled again. Changing the definitions of primitives does not happen
often--indeed hardly ever--but the possibility must be accounted for.

## JavaScrpt as a Scheme Runtime

It's interesting to note
the degree of correspondence between Scheme's runtime and the JavaScript runtime.
You could hardly design a better Scheme runtime if you tried:

Dynamically typed: Check.

Garbage collector: Check.

Strings, numbers, booleans and Functions: Check. I threw in BigInt for fun. "Factoral" likes it.

Function are data. Check. You can create a Function from a string and get the string body
of a function.

Atoms: Check. They're Symbols (in the ATOMS dictionary).

Scopes: Check. I use the prototype chain and JavaScript resolves it just as it would
any ordinary "this.foo" reference. This is something JITs slave over. In compiled code,
SchemeJS scopes are ordinary JavaScript scopes.

Closures: Check. SchemeJS closures are JavaScript closures.

Cons cells and nil? Those are really the only things missing and I use JavaScript classes
for those... and threw in lazily-evaluated CAR and CDR references for fun.

(Unfortunately, while JavaScript has an internal set-where-found-in-scope primitive, it doesn't
appear to be accessible to user code in any useful way. This is the _only_ runtime
feature I had to emulate. Real Scheme/Lisp programmers don't use set anyway. But note that the
SchemeJS compiler doesn't need it, so compiled Scheme doesn't suffer any emulation penalty.)

In short, the JavaScript runtime is ideal for Scheme--_much_ better than a Java VM--because
it has dynamic types, the right sorts of primitive types, real closures, no need for "boxing"
(anyway, it's transparent to users and highly-optimized)
and implements something that can be used for scope resolution as a highly-optimized primitive.
All it needs is cons cells, nil, an interpreter, a parser, a "printer", a REPL, a compiler, a Scheme JIT
and a handful of Lisp primitives. Hence this project. There's no emulation layer because
there's nothing to emulate (save "set/setq").

I didn't set out to write a surprisingly fast Scheme implementation, but halfway into implementing
it I realized it inevitably would be, thanks to the JavaScript runtime and its JITs.

Probably the best way to think about it is that JavaScript was secretly Scheme all along,
just as Brendan Eich originally intended. Recent improvements in ES6 and beyond have exposed more of the underlying Lispyness and this project wouldn't have been attempted without them.
You could argue that JavaScript is, in fact, a [Lisp 2](https://en.wikipedia.org/wiki/LISP_2).
It's as if Scheme and Self had an unlikely affair and decided their lovechild would
have a vaguely Java-like syntax.

An alternate, and very useful, way to think about it is that SchemeJS is an AST for JavaScript
that happens to be executable and has a compiler and a JIT. You can easily target other languages
to SchemeJS and get an interpreter, compiler and JIT for free!

## Coding Conventions

Generally, variable, function and class names are camel case. An exception
is when a function is also a Scheme function with dashes in its name. In that case
the function uses an underscore where a dash occurs in the Scheme name.

Constants are all-caps. Strings are generally "str" if they are for humans; and 'str'
if they're for internal purposes; \`str\` is used when convenient, as it quite frequently is.

I use "== null" specifically to test for "nullish" (undefined and null). Be careful
with null since it reports its type as "object" but doesn't do objecty things. Otherwise
I use ===.

"Let" is used rather than "var." "var" is forbidden.

I prefer to define functions _after_ they're used. Tell the big picture first, then details.
Often a function will have a broad API, process its arguments and options, then call
a mini-me version of itself defined locally. This gets the grubby stuff out of
the way and then the function can, for instance, recurse on the simpler API and common
arguments don't need to be passed around but instead can be accessed from the containing scope.

I prefer arrow functions for one-liners, regular functions for longer things. for situations
where an own "this" is required, or where a forward reference is needed.

I don't use "const" for things that just happen to be const, for instance loop indexes;
that's just too damn fussy. I use it for things that _should_ be const or _must_ be const.
Sometimes I use const to make it trivial for JITs to discover that sonething cannot change or,
in the case of selectable options like the SchemeJS JIT and TRACE_INTERPRETER, so that JITs can easily
DCE the optional code. "const" should convey important information to the human,
the machine, or both; otherwise it's just noise.

Instead of passing in booleans and other unnamed values as parameters (foo(3, true, false, 17))
I generally try to assign the value to a variable so that it has a name then pass that variable.
If a function has more than a few obvious parameters, I usually pass an "opts" object instead
so that parameters can be named entries in the opts argument. Usually, the first thing the function
does is access the options, assign them to variables and provide a default. This gets that
out of the way up front and provides documentation on what the options are.

## Future Work

First, more extensive unit and scenario tests.

I have plans for a non-recursive interpreter and tail-call-optimization in both the
interpretrer and compiler.

Make let, let* and letrec distinct, I think. They're all implemented as letrec currently.
No good reason to do it except that it could cause some existing SIOD code to break if I don't.
Three different "let" primitives was a mistake from the outset, IMO;
all you really need is "letrec."

It would be nice to support writing async and generator functions naturally but I haven't
given it much thought beyond the observation that a non-recursive interpreter would make "yield" pretty straightforward. Compiling it would require a different approach, I suspect.
Probably transform the Scheme into a series of continuations and compile those the usual way.
I imagine this is what JavaScript implementations do at the AST level. At least I have the
advantage that Scheme code is an AST inherently.

I may revisit "rest" parameters. I like the current notation, but there's no good way
to have a lambda with just a rest parameter (yes, it technically encroaches on Curry notation
but that would not be a good notation anyway),
On the other hand,
I've found it useful to always have at least two required parameters since then
you leave open the possibility of creating a partial application closure. So maybe
it isn't so useful after all. On the other other hand, some of the builtins do have just a rest
parameter. So it's an open question.

Urgently needed: Generate dynamic source maps to enable debugging!
https://stackoverflow.com/questions/49463047/source-map-for-a-dynamically-created-function
https://kybernetikos.github.io/jsSandbox/srcmaps/dynamic.html